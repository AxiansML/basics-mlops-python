{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"resume_checkpoint\": \"None\",  # \"restored_model_checkpoint/checkpoint_epoch=06.ckpt\",\n",
    "    \"resume_run_id\": \"None\",  # \"ef539b4138fa4055bf65c58f30249211\",\n",
    "    \"max_epochs\": 10,\n",
    "    \"gpus\": 0,\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 0.0001,\n",
    "    \"num_samples\": -1,\n",
    "    \"val_ratio\": 0.2,\n",
    "    \"test_ratio\": 0,\n",
    "    \"random_seed\": \"None\",\n",
    "    \"dataset\": \"/dbfs/FileStore/tables/datasets/dummy.json\",\n",
    "    # \"dataset\": os.path.join(os.getenv(\"PROCESSED_DATA_DIR\"), \"dummy.json\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two options for the backend_config: None to run locally or configure a cluster to run on databricks\n",
    "# https://docs.databricks.com/dev-tools/api/latest/clusters.html\n",
    "# Change the configuration accordingly to AWS, Azure, Google Cloud\n",
    "\n",
    "# backend_config = None\n",
    "\n",
    "backend_config = {\n",
    "    \"num_workers\": 0,\n",
    "    \"spark_version\": \"12.1.x-scala2.12\",\n",
    "    \"spark_conf\": {\n",
    "        \"spark.master\": \"local[*, 4]\",\n",
    "        \"spark.databricks.cluster.profile\": \"singleNode\"\n",
    "    },\n",
    "    \"azure_attributes\": {\n",
    "        \"first_on_demand\": 1,\n",
    "        \"availability\": \"ON_DEMAND_AZURE\",\n",
    "        \"spot_bid_max_price\": -1\n",
    "    },\n",
    "    \"node_type_id\": \"Standard_F4\",\n",
    "    \"driver_node_type_id\": \"Standard_F4\",\n",
    "    \"ssh_public_keys\": [],\n",
    "    \"custom_tags\": {\n",
    "        \"ResourceClass\": \"SingleNode\"\n",
    "    },\n",
    "    \"spark_env_vars\": {\n",
    "        \"PYSPARK_PYTHON\": \"/databricks/python3/bin/python3\",\n",
    "        \"LOGS_DIR\": \"/logs\",\n",
    "        \"LOGGER_LEVEL\": \"INFO\"\n",
    "    },\n",
    "    \"enable_elastic_disk\": \"true\",\n",
    "    \"cluster_source\": \"UI\",\n",
    "    \"init_scripts\": [],\n",
    "    \"single_user_name\": \"alexandre1.almeida@axians.com\",\n",
    "    \"data_security_mode\": \"LEGACY_SINGLE_USER_STANDARD\",\n",
    "    \"runtime_engine\": \"STANDARD\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set databricks env variables\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"databricks\"\n",
    "\n",
    "# Set github access uri\n",
    "user = os.getenv(\"GIT_USER\")\n",
    "token = os.getenv(\"GIT_TOKEN\")\n",
    "git_uri = os.getenv(\"GIT_URI\")\n",
    "uri = f\"https://{user}:{token}@{git_uri}\"\n",
    "git_branch = \"main\"\n",
    "\n",
    "# uri = os.getenv(\"ROOT_DIR\") # Uncomment if using the local filesystem path\n",
    "\n",
    "experiment_name = os.getenv(\"EXP_NAME\")\n",
    "experiment = mlflow.set_experiment(experiment_name)\n",
    "backend = \"databricks\" # Comment if using local backend\n",
    "# backend = \"local\" # Uncomment if using local backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/03/02 15:24:04 INFO mlflow.projects.utils: === Fetching project from https://alexandre1-almeida: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@github.com/AxiansML/basics-mlops-python.git into /var/folders/p6/5l5fzz397vq3lwg4c8p3t7lw0000gn/T/tmpkuib3806 ===\n",
      "2023/03/02 15:24:06 INFO mlflow.projects.databricks: === Creating tarball from /var/folders/p6/5l5fzz397vq3lwg4c8p3t7lw0000gn/T/tmpkuib3806 in temp directory /var/folders/p6/5l5fzz397vq3lwg4c8p3t7lw0000gn/T/tmp2uh__v2t ===\n",
      "2023/03/02 15:24:06 INFO mlflow.projects.databricks: === Total file size to compress: 1267.8 KB ===\n",
      "2023/03/02 15:24:07 INFO mlflow.projects.databricks: === Uploading project tarball (size: 1020.8 KB) to /dbfs/mlflow-experiments/4457423338043857/projects-code/22cd8988021b5758aa6e8e722feec97876ea040f532f9800ce38f7eb87908795.tar.gz ===\n",
      "2023/03/02 15:24:07 INFO mlflow.projects.databricks: === Uploading project to DBFS path /dbfs/mlflow-experiments/4457423338043857/projects-code/22cd8988021b5758aa6e8e722feec97876ea040f532f9800ce38f7eb87908795.tar.gz ===\n",
      "2023/03/02 15:24:07 INFO mlflow.projects.databricks: === Finished uploading project to /dbfs/mlflow-experiments/4457423338043857/projects-code/22cd8988021b5758aa6e8e722feec97876ea040f532f9800ce38f7eb87908795.tar.gz ===\n",
      "2023/03/02 15:24:07 INFO mlflow.projects.databricks: === Running entry point train of project https://alexandre1-almeida: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@github.com/AxiansML/basics-mlops-python.git on Databricks ===\n",
      "2023/03/02 15:24:07 INFO mlflow.projects.databricks: === Submitting a run to execute the MLflow project... ===\n",
      "2023/03/02 15:24:08 INFO mlflow.projects.databricks: === Launched MLflow run as Databricks job run with ID 23364. Getting run status page URL... ===\n",
      "2023/03/02 15:24:08 INFO mlflow.projects.databricks: === Check the run's status at https://adb-32025867620321.1.azuredatabricks.net/?o=32025867620321#job/907723020123954/run/23364 ===\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.001]  # , 0.0005, 0.0001, 0.00005, 0.00001, 0.000005, 0.000001]\n",
    "\n",
    "for lr in lrs:\n",
    "    hyperparams[\"lr\"] = lr\n",
    "\n",
    "    mlflow.projects.run(\n",
    "        uri,\n",
    "        version=git_branch, # Comment if using the local filesystem path\n",
    "        entry_point=\"train\",\n",
    "        # env_manager=\"local\",\n",
    "        parameters=hyperparams,\n",
    "        backend=backend,\n",
    "        backend_config=backend_config,\n",
    "        experiment_id=experiment.experiment_id,\n",
    "        synchronous=False,  # Set to False, if you don't want to wait for the model to train\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basics-mlops-python-VGYzWtQD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b12b50d9504b24a4188b7e3798fc1ee42952b0a338d10754aff4b0930121ba22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
