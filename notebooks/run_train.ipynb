{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"resume_checkpoint\": \"None\",  # \"restored_model_checkpoint/checkpoint_epoch=06.ckpt\",\n",
    "    \"resume_run_id\": \"None\",  # \"ef539b4138fa4055bf65c58f30249211\",\n",
    "    \"max_epochs\": 10,\n",
    "    \"gpus\": 0,\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 0.0001,\n",
    "    \"num_samples\": -1,\n",
    "    \"val_ratio\": 0.2,\n",
    "    \"test_ratio\": 0,\n",
    "    \"random_seed\": \"None\",\n",
    "    \"dataset\": \"/dbfs/FileStore/tables/datasets/dummy.json\",\n",
    "    # \"dataset\": \"data/processed/dummy.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two options: None to run locally or configure a cluster to run on databricks\n",
    "# https://docs.databricks.com/dev-tools/api/latest/clusters.html\n",
    "# Change the configuration accordingly to AWS, Azure, Google Cloud\n",
    "# backend_config = None\n",
    "\n",
    "backend_config = {\n",
    "    \"num_workers\": 0,\n",
    "    \"spark_version\": \"10.4.x-scala2.12\",\n",
    "    \"spark_conf\": {\n",
    "        \"spark.databricks.cluster.profile\": \"singleNode\",\n",
    "        \"spark.master\": \"local[*, 4]\",\n",
    "    },\n",
    "    \"azure_attributes\": {\n",
    "        \"first_on_demand\": 1,\n",
    "        \"availability\": \"ON_DEMAND_AZURE\",\n",
    "        \"spot_bid_max_price\": -1,\n",
    "    },\n",
    "    \"node_type_id\": \"Standard_F4\",\n",
    "    \"driver_node_type_id\": \"Standard_F4\",\n",
    "    \"ssh_public_keys\": [],\n",
    "    \"custom_tags\": {\"ResourceClass\": \"SingleNode\"},\n",
    "    \"spark_env_vars\": {\"PYSPARK_PYTHON\": \"/databricks/python3/bin/python3\"},\n",
    "    \"enable_elastic_disk\": \"true\",\n",
    "    \"cluster_source\": \"UI\",\n",
    "    \"init_scripts\": [],\n",
    "    \"cluster_id\": \"0519-085431-rvfc7gfq\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set databricks env variables\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"databricks\"\n",
    "\n",
    "# Set github access uri\n",
    "user = os.getenv(\"GIT_USER\")\n",
    "token = os.getenv(\"GIT_TOKEN\")\n",
    "git_uri = os.getenv(\"GIT_URI\")\n",
    "uri = f\"https://{user}:{token}@{git_uri}\"\n",
    "git_branch = \"main\"\n",
    "\n",
    "# Local filesystem path\n",
    "# uri = \"/Users/alexmfalm/Documents/Git_Repos/basics-mlops-python\"\n",
    "\n",
    "experiment_name = os.getenv(\"EXP_NAME\")\n",
    "experiment = mlflow.set_experiment(experiment_name)\n",
    "backend = \"databricks\"  # local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/28 16:19:08 INFO mlflow.projects.utils: === Fetching project from https://alexandre1-almeida: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@github.com/AxiansML/basics-mlops-python into /var/folders/p6/5l5fzz397vq3lwg4c8p3t7lw0000gn/T/tmp6lit73ze ===\n",
      "2022/09/28 16:19:11 INFO mlflow.projects.databricks: === Creating tarball from /var/folders/p6/5l5fzz397vq3lwg4c8p3t7lw0000gn/T/tmp6lit73ze in temp directory /var/folders/p6/5l5fzz397vq3lwg4c8p3t7lw0000gn/T/tmp2e3vcqs8 ===\n",
      "2022/09/28 16:19:11 INFO mlflow.projects.databricks: === Total file size to compress: 352.6 KB ===\n",
      "2022/09/28 16:19:11 INFO mlflow.projects.databricks: === Uploading project tarball (size: 203.3 KB) to /dbfs/mlflow-experiments/4457423338043857/projects-code/c01361f96c8380f1afa7d6370b284c07fdb9d485775943d5c6da99b29fe3a433.tar.gz ===\n",
      "2022/09/28 16:19:11 INFO mlflow.projects.databricks: === Uploading project to DBFS path /dbfs/mlflow-experiments/4457423338043857/projects-code/c01361f96c8380f1afa7d6370b284c07fdb9d485775943d5c6da99b29fe3a433.tar.gz ===\n",
      "2022/09/28 16:19:11 INFO mlflow.projects.databricks: === Finished uploading project to /dbfs/mlflow-experiments/4457423338043857/projects-code/c01361f96c8380f1afa7d6370b284c07fdb9d485775943d5c6da99b29fe3a433.tar.gz ===\n",
      "2022/09/28 16:19:11 INFO mlflow.projects.databricks: === Running entry point train of project https://alexandre1-almeida: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@github.com/AxiansML/basics-mlops-python on Databricks ===\n",
      "2022/09/28 16:19:11 INFO mlflow.projects.databricks: === Submitting a run to execute the MLflow project... ===\n",
      "2022/09/28 16:19:12 INFO mlflow.projects.databricks: === Launched MLflow run as Databricks job run with ID 30104. Getting run status page URL... ===\n",
      "2022/09/28 16:19:12 INFO mlflow.projects.databricks: === Check the run's status at https://adb-32025867620321.1.azuredatabricks.net/?o=32025867620321#job/1090839203199280/run/30104 ===\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.001]  # , 0.0005, 0.0001, 0.00005, 0.00001, 0.000005, 0.000001]\n",
    "\n",
    "for lr in lrs:\n",
    "    hyperparams[\"lr\"] = lr\n",
    "\n",
    "    mlflow.projects.run(\n",
    "        uri,\n",
    "        version=git_branch,\n",
    "        entry_point=\"train\",\n",
    "        # env_manager=\"local\",\n",
    "        parameters=hyperparams,\n",
    "        backend=backend,\n",
    "        backend_config=backend_config,\n",
    "        experiment_id=experiment.experiment_id,\n",
    "        synchronous=False,  # Set to False, if you don't want to wait for the model to train\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('basics-mlops-python-VGYzWtQD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b12b50d9504b24a4188b7e3798fc1ee42952b0a338d10754aff4b0930121ba22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
