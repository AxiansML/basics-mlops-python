{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"resume_checkpoint\": \"None\",  # \"restored_model_checkpoint/checkpoint_epoch=06.ckpt\",\n",
    "    \"resume_run_id\": \"None\",  # \"ef539b4138fa4055bf65c58f30249211\",\n",
    "    \"max_epochs\": 10,\n",
    "    \"gpus\": 0,\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 0.0001,\n",
    "    \"num_samples\": -1,\n",
    "    \"val_ratio\": 0.2,\n",
    "    \"test_ratio\": 0,\n",
    "    \"random_seed\": \"None\",\n",
    "    # \"dataset\": \"/FileStore/tables/datasets/dummy.json\",\n",
    "    \"dataset\": \"data/processed/dummy.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbackend_config = {\\n    \"num_workers\": 0,\\n    \"spark_version\": \"10.4.x-scala2.12\",\\n    \"spark_conf\": {\\n        \"spark.databricks.cluster.profile\": \"singleNode\",\\n        \"spark.master\": \"local[*, 4]\",\\n    },\\n    \"azure_attributes\": {\\n        \"first_on_demand\": 1,\\n        \"availability\": \"ON_DEMAND_AZURE\",\\n        \"spot_bid_max_price\": -1,\\n    },\\n    \"node_type_id\": \"Standard_F4\",\\n    \"driver_node_type_id\": \"Standard_F4\",\\n    \"ssh_public_keys\": [],\\n    \"custom_tags\": {\"ResourceClass\": \"SingleNode\"},\\n    \"spark_env_vars\": {\"PYSPARK_PYTHON\": \"/databricks/python3/bin/python3\"},\\n    \"enable_elastic_disk\": \"true\",\\n    \"cluster_source\": \"UI\",\\n    \"init_scripts\": [],\\n    \"cluster_id\": \"0519-085431-rvfc7gfq\",\\n}\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Two options: None to run locally or configure a cluster to run on databricks\n",
    "# https://docs.databricks.com/dev-tools/api/latest/clusters.html\n",
    "# Change the configuration accordingly to AWS, Azure, Google Cloud\n",
    "backend_config = None\n",
    "\"\"\"\n",
    "backend_config = {\n",
    "    \"num_workers\": 0,\n",
    "    \"spark_version\": \"10.4.x-scala2.12\",\n",
    "    \"spark_conf\": {\n",
    "        \"spark.databricks.cluster.profile\": \"singleNode\",\n",
    "        \"spark.master\": \"local[*, 4]\",\n",
    "    },\n",
    "    \"azure_attributes\": {\n",
    "        \"first_on_demand\": 1,\n",
    "        \"availability\": \"ON_DEMAND_AZURE\",\n",
    "        \"spot_bid_max_price\": -1,\n",
    "    },\n",
    "    \"node_type_id\": \"Standard_F4\",\n",
    "    \"driver_node_type_id\": \"Standard_F4\",\n",
    "    \"ssh_public_keys\": [],\n",
    "    \"custom_tags\": {\"ResourceClass\": \"SingleNode\"},\n",
    "    \"spark_env_vars\": {\"PYSPARK_PYTHON\": \"/databricks/python3/bin/python3\"},\n",
    "    \"enable_elastic_disk\": \"true\",\n",
    "    \"cluster_source\": \"UI\",\n",
    "    \"init_scripts\": [],\n",
    "    \"cluster_id\": \"0519-085431-rvfc7gfq\",\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You must create a config file, containing your databricks and github access tokens and\n",
    "# the mlflow tracking experiment name. DON'T PUSH THIS FILE TO THE REMOTE REPO!\n",
    "with open(\"../mlflow_config.yaml\") as f:\n",
    "    mlflow_config = yaml.safe_load(f)\n",
    "\n",
    "# Set databricks env variables\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"databricks\"\n",
    "os.environ[\"DATABRICKS_HOST\"] = mlflow_config[\"db_host\"]\n",
    "os.environ[\"DATABRICKS_TOKEN\"] = mlflow_config[\"db_token\"]\n",
    "\n",
    "# Set github access uri\n",
    "# user = mlflow_config[\"git_user\"]\n",
    "# token = mlflow_config[\"git_token\"]\n",
    "# git_uri = mlflow_config[\"git_uri\"]\n",
    "# uri = f\"https://{user}:{token}@{git_uri}\"\n",
    "uri = (\n",
    "    \"/Users/alexmfalm/Documents/Git_Repos/basics-mlops-python\"  # Local filesystem path\n",
    ")\n",
    "# git_branch = \"main\"\n",
    "\n",
    "experiment_name = mlflow_config[\"exp_name\"]\n",
    "experiment = mlflow.set_experiment(experiment_name)\n",
    "backend = \"local\"  # databricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/28 14:32:49 INFO mlflow.projects.utils: === Created directory /var/folders/p6/5l5fzz397vq3lwg4c8p3t7lw0000gn/T/tmp995qjujp for downloading remote URIs passed to arguments of type 'path' ===\n",
      "2022/09/28 14:32:49 INFO mlflow.utils.databricks_utils: No workspace ID specified; if your Databricks workspaces share the same host URL, you may want to specify the workspace ID (along with the host information in the secret manager) for run lineage tracking. For more details on how to specify this information in the secret manager, please refer to the Databricks MLflow documentation.\n",
      "2022/09/28 14:32:49 INFO mlflow.projects.backend.local: === Running command 'python src/train.py \\\n",
      "  --resume_checkpoint None \\\n",
      "  --resume_run_id None \\\n",
      "  --max_epochs 10 \\\n",
      "  --gpus 0 \\\n",
      "  --batch_size 32 \\\n",
      "  --lr 0.001 \\\n",
      "  --num_samples -1 \\\n",
      "  --val_ratio 0.2 \\\n",
      "  --test_ratio 0 \\\n",
      "  --random_seed None \\\n",
      "  --dataset data/processed/dummy.json' in run with ID '3b6798fa4f504a71b5821453acec03fb' === \n",
      "2022/09/28 14:32:53 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of pytorch. If you encounter errors during autologging, try upgrading / downgrading pytorch to a supported version, or try upgrading MLflow.\n",
      "/Users/alexmfalm/.local/share/virtualenvs/basics-mlops-python-VGYzWtQD/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2022/09/28 14:32:54 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '3b6798fa4f504a71b5821453acec03fb', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pytorch workflow\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "  | Name       | Type    | Params\n",
      "---------------------------------------\n",
      "0 | linear_reg | Linear  | 2     \n",
      "1 | loss       | MSELoss | 0     \n",
      "---------------------------------------\n",
      "2         Trainable params\n",
      "0         Non-trainable params\n",
      "2         Total params\n",
      "0.000     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 0it [00:00, ?it/s]                                                "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexmfalm/.local/share/virtualenvs/basics-mlops-python-VGYzWtQD/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1892: PossibleUserWarning: The number of training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/4 [00:00<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W reducer.cpp:1258] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  75%|███████▌  | 3/4 [00:06<00:02,  2.18s/it, loss=7.57e+05, v_num=1]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0: 100%|██████████| 4/4 [00:17<00:00,  4.26s/it, loss=7.57e+05, v_num=1]\n",
      "Epoch 0: 100%|██████████| 4/4 [00:17<00:00,  4.26s/it, loss=7.57e+05, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric epoch_val_score improved. New best score: -29855.068\n",
      "Epoch 0, global step 3: 'epoch_val_score' reached -29855.06836 (best -29855.06836), saving model to '/Users/alexmfalm/Documents/Git_Repos/basics-mlops-python/checkpoints/epoch=0-step=3.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  75%|███████▌  | 3/4 [00:21<00:07,  7.02s/it, loss=3.9e+09, v_num=1] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1: 100%|██████████| 4/4 [00:31<00:00,  7.92s/it, loss=3.9e+09, v_num=1]\n",
      "Epoch 1: 100%|██████████| 4/4 [00:31<00:00,  7.92s/it, loss=3.9e+09, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 6: 'epoch_val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  75%|███████▌  | 3/4 [00:20<00:06,  6.94s/it, loss=2.44e+13, v_num=1]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2: 100%|██████████| 4/4 [00:31<00:00,  7.95s/it, loss=2.44e+13, v_num=1]\n",
      "Epoch 2: 100%|██████████| 4/4 [00:31<00:00,  7.95s/it, loss=2.44e+13, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 9: 'epoch_val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3:  75%|███████▌  | 3/4 [00:20<00:06,  6.84s/it, loss=8.78e+16, v_num=1]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Validation:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Validation DataLoader 0:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3: 100%|██████████| 4/4 [00:30<00:00,  7.72s/it, loss=8.78e+16, v_num=1]\n",
      "Epoch 3: 100%|██████████| 4/4 [00:30<00:00,  7.72s/it, loss=8.78e+16, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric epoch_val_score did not improve in the last 3 records. Best score: -29855.068. Signaling Trainer to stop.\n",
      "Epoch 3, global step 12: 'epoch_val_score' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 4/4 [00:31<00:00,  7.78s/it, loss=8.78e+16, v_num=1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/09/28 14:35:19 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"/Users/alexmfalm/.local/share/virtualenvs/basics-mlops-python-VGYzWtQD/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\"\n",
      "2022/09/28 14:35:21 INFO mlflow.projects: === Run (ID '3b6798fa4f504a71b5821453acec03fb') succeeded ===\n"
     ]
    }
   ],
   "source": [
    "lrs = [0.001]  # , 0.0005, 0.0001, 0.00005, 0.00001, 0.000005, 0.000001]\n",
    "\n",
    "for lr in lrs:\n",
    "    hyperparams[\"lr\"] = lr\n",
    "\n",
    "    mlflow.projects.run(\n",
    "        uri,\n",
    "        # version=git_branch,\n",
    "        entry_point=\"train\",\n",
    "        env_manager=\"local\",\n",
    "        parameters=hyperparams,\n",
    "        backend=backend,\n",
    "        backend_config=backend_config,\n",
    "        experiment_id=experiment.experiment_id,\n",
    "        synchronous=True,  # Set to False, if you don't want to wait for the model to train\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('basics-mlops-python-VGYzWtQD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b12b50d9504b24a4188b7e3798fc1ee42952b0a338d10754aff4b0930121ba22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
